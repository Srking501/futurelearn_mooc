---
title: 'CSC8631 Project: Learning Anaylitcs'
author: "Abdullah Turki H Alshadadi, 190582184"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath(".."))
```

``` {r ProjectTemplate, include=FALSE}
library(ProjectTemplate)
load.project()
```

## Introduction

This report is a data mining report exploring the online course of 
"Cybersecurity: Safety At Home, Online, and in life" - which was created by 
[Newcastle University](https://www.ncl.ac.uk) published in 
[FutureLearn](https://www.futurelearn.com/) educational platform.

It will be structured in the method of CRISP-DM (Cross-Industry Standard 
Process for Data Mining), where it will discuss the Business Understanding,
Data Understanding, Data Preparation, Modelling, Evaluation and Deployment 
from the given data.

Due to following the CRISP-DM, there will be cycles around the previously 
discussed headings because of better built understanding of the business 
intentions with the current focused data that needs more insight, or because 
limitation of data to meet the business needs, or even because of a better 
understanding on the data that shows significant importance to the business 
that the business intentions are changed to meet align more to the data.


# Cycle 1

## **Business Understanding 1**

### Determining Business Objectives: Background 1

This online course is about the discipline Cybersecurity made by 
Newcastle University, a high education provider that seeks to make the course 
publicly accessible by individuals through the educational online platform 
FutureLearn.

FutureLearn provides the platform to host the online course with the benefit
of providing Newcastle University with learning data of participating 
individuals on their course.

Using the provided raw data from FutureLearn, Newcastle University will likely 
want to derive insights on how "successful" is the learning design of the 
course, did most individuals pass the online course and did it increase over
the life time of the course?


### Determining Business Objectives: Business Objectives 1

FutureLearn's raw data of the online course needs insights to be able to quantify
measurements of participating individuals engagement on the course for Newcastle
University.

Through data analysis, Newcastle University will likely want to know the 
how "successful" is the engagement of the course, in terms whether the
the participants have pass or not. This is important 
because it will show the effectiveness of their course and determine the 
best run in the online course.

### Determining Business Objectives: Business Success Criteria 1

The following is the possible success criteria of Newcastle University:

* "How successful was the online course; has it improved over new runs of the
course?"
  
### Assessing Situation: Inventory of Resources 1

The given data is 7 runs of the online course from September 2016 to
February 2018, where it is not expected to have more data from the 
FutureLearn as [currently Newcastle University stopped the online course](https://www.futurelearn.com/courses/cyber-security).
Therefore, management of resources are much easier and manageable as the only
data to be concern with is the provided 7 runs data.


### Assessing Situation: Requirements, assumptions, and constraints 1

For requirements, there is a deadline of submission for
this report, limiting the chance of deep data exploration. Thus, the report will 
focus on the basic vital needs to meet the [Newcastle Univesity's success criteria](#determining-business-objectives-business-success-criteria-1).

For assumptions, the models for the data should be presented in way where it can
show trends and variance in the data, so that it will be possible to explain to
a novice statistician or user from Newcastle University's online course 
designers' to understand the success of their course while retaining solid 
statistical foundation.


Lastly, there is no constraints on the use of the given raw data
from FutureLearn, but the only issue is that this is the only data that will be
provided.


### Assessing Situation: Risks and Contingencies 1

There is the risk of data not showing results of that convey passed or failed 
participants, but rather show other factors such as the participants 
satisfaction or engagement in the sense that they have partaken 
in the activities of the course. For that, the plan is to adjust to these 
types of data factors and readjust the 
[Newcastle University's success criteria](#determining-business-objectives-business-success-criteria-1) to reflect
better to the data and the [business needs](#determining-business-objectives-business-objectives-1).

Furthermore, there is risk of the data to be lost or corrupted, thus a backup is
made for the data away from the [ProjectTemplate](http://projecttemplate.net/)
`data` folder just in case if a mistake is made, and everything is stored in 
the cloud by [OneDrive](https://www.microsoft.com/en-gb/microsoft-365/onedrive/online-cloud-storage) provided by Newcastle University.


### Assessing Situation: Terminology 1

There is no set of business terminologies to be aware of, therefore, there 
should not be any special terms that contain exclusive meanings in the data by
Newcastle University or FutureLearn.


### Assessing Situation: Cost and Benefits 1

There is no cost on this project, in terms of financial cost but instead it is a 
workflow cost, where this data mining project is heavily limited by time.
However, the benefits are that Newcastle University would have a better 
understanding on the performance of their online course.


### Determining Data Mining Goals: Data Mining Goals 1

Gain insights on the data to determine what constitutes as "success" in the 
online course by concept description and classify those who have passed or 
those who have not passed.


### Determining Data Mining Goals: Data Mining Success Criteria 1

Models that can identify the percentage of passed or not passed participants 
using the "success" data to show and view the change of "success" over the 7 runs 
of the course to see if it has decreasing over time or not, and what run was
that has the most "success". 
This would likely help to show how effective is the course 
for Newcastle University over the span of 7 runs and identify the best run in
the online course.


## **Data Understanding 1**

### Describing Data: Data Description Report 1

Before describing the data, there is the need to describe how the online
course is structured. The online course duration is 3 weeks, therefore it 
consists of 3 main sections which are "Exploring personal privacy online", 
"Online payment security" and "Security in the future home".

Within each section, there is what the Newcastle University and FutureLearn 
called "steps", which is the main subsection activities to do in the 
online course, and it also contains a "step number" that shows the participant 
the total activities to do per sections.

These step activities are catogrise into ARTICLE, DISCUSSION, EXERCISE, QUIZ,
TEST and VIDEO.

For first run, it is structured like so:

  * Section 1 "Exploring personal privacy online"
    * Steps 1.1 to 1.18, which has the step number of 18
    * It contains 9 ARTICLE, 2 DISCUSSION, 1 EXCERCISE, 1 QUIZ and 5 VIDEO
    
  * Section 2 "Online payment security"
    * Steps 2.1 to 2.21, which has the step number of 21
    * It contains 13 ARTICLE, 2 DISCUSSION, 1 EXCERCISE, 2 QUIZ and 3 VIDEO
    
  * Section 3 "Security in the future home"
    * Steps 3.1 to 3.21, which has the step number of 21
    * It contains 10 ARTICLE, 4 DISCUSSION, 1 EXCERCISE, 1 QUIZ, 1 TEST and 
    4 VIDEO
    
For the second run, there are steps been added to Section 2 and Section 3:

  * Section 1 "Exploring personal privacy online"
    * Step 1.2 "Why are you here? DISCUSSION" is the new step, making the steps
    number to become 19, which means the steps are 1.1 to 1.19
    * It added 1 ARTICLE
    
  * Section 2 "Online payment security"
    * Step 2.11 "Exploring vulnerabilities in online payments VIDEO (05:12)" 
    and step 2.22 "Auditing your Mobile App permissions ARTICLE" are the new 
    step, making the steps number to become 23, which means the steps are 2.1 
    to 1.22
    * It added 1 ARTICLE and 1 VIDEO
    
Then for the third run a step has been removed:

  * Section 3 "Security in the future home"
    * Step 3.21 "Glossary and references ARTICLE" is the removed step, making 
    the steps number to become 20, which means the steps are 3.1 to 3.21
    * It removed 1 ARTICLE

After understanding the online course terminology, the description of data will
be discussed.

For the first run of the online course, the data from FutureLearn is split into 
6 data frames:

  1. `cyber.security.1_archetype.survey.responses`
  
  2. `cyber.security.1_enrolments`
  
  3. `cyber.security.1_leaving.survey.responses`
  
  4. `cyber.security.1_question.response`
  
  5. `cyber.security.1_step.activity`
  
  6. `cyber.security.1_weekly.sentiment.survey.responses`
  
  
Then in the second run of the online course, the data from FutureLearn has 
expanded to include:

  7. `cyber.security.2_team.members`
  
Lastly, the third run of the online course, the data from FutureLearn has 
once more expanded to include:

  8. `cyber.security.3_video.stats`

  
#### 1.

Archetypes are list of categorical data that describes the behaviour and 
personality of the participants of the course, and these archetypes are 
Advancers, Explorers, Fixers, Flourishers, Hobbyists, Preparers and Vitalisers
(there is also the options to pick Other).

However, this data set would unlikely be useful as it shows personal character
traits which is more appropriate for marketing purpose especially if the 
business (that is Newcastle University) would like to have more participants
to the course it would target archetypes of users - with more supporting data - 
that has the most engagement (for example, successfully completing the whole 
course) to market for.

In contrast, from [Business Understanding section](#business-understanding-1), 
Newcastle University would prefer to understand if their online course was 
simply "successful", in the sense that the participants have passed the online
course, on the 7 runs of the course.

#### 2.

The data set that keeps track of the participants of the online course. Where 
the most interesting columns are `learner_id` that 
provides a unique code for referencing individual participants 
and `fully_participated_at` that verify that a participant have fully 
completed the course.

#### 3.

Data set that includes participants that have left the course without 
completing it. It contains data that verifies the time the participants have
left, their reasoning, last completed step in the course, last completed week of
the course and last completed step number.

This could be useful for another in depth analysis to pinpoint why did the 
participant not complete the course and what step or step number they were 
in before they left, to infer need of improvements for the sections that has 
the most leaving response.

#### 4.

This data keeps track of the quiz or test subsections responses from
participants in the online course. It shows what step number the quiz or 
test was that might be useful to link it back to the leaving response to 
figure out if the quiz and test were the discouraging problem that participants
had, or link it back to the step activity that keeps track on the step the 
participants have done which is useful to determine why some participants have 
performed better than others.

It also contains a column, `correct`, which shows if the participant have 
answered the question of a quiz or test correctly or not. This is especially 
useful to determine the total passed participants in the course to meet 
[Newcastle University's success criteria](#determining-business-objectives-business-success-criteria-1).

#### 5.

For this data, it keeps track of what step activity of the online course is the
participant is in, when did the participant started it and when did the 
participant have finished the step activity.

This could also be useful to keep track of the engagement the participants and 
can be useful to also link it back to the leave response to determine what was
the most discouraging section out of the online course.

#### 6.

This data keeps track of the weekly responses on the online course to determine
the participants experience for what week section there are in. It contains 
rating system, called `experience_rating`, and a response, `reason`, of the 
picked rating system.

#### 7.

This data lacks enough information to understand what is trying to represent. 
An educated guess that it could be for representing the Newcastle University 
staff who keeps track of the online course and perhaps questions or feedback
from the participants. This is because in the column `team_role` it 
classifies the individuals in the data frame as `host`, `lead_educator`,
`educator`, `mentor`, `reviewer` and `facilitator`.

#### 8.

This data keeps track of the video statistics. It contains a lot of 
informative numerical statistics about the videos.

It shows the videos duration in the online course in seconds - this was verified 
by document image shot provided by Newcastle University of how the online course 
looked like, for example the first video in the online course contains the 
number format of "01:39" which is usually representing "minutes:seconds", and 
1 minute and 39 seconds in seconds are in total 99 seconds.

From the other stats, the most interesting are the following:

  * `total_views`
  
  * `viewed_five_percent`
  
  * `viewed_ten_percent`
  
  * `viewed_twentyfive_percent`
  
  * `viewed_fifty_percent`
  
  * `viewed_seventyfive_percent`
  
  * `viewed_ninetyfive_percent`
  
  * `viewed_onehundred_percent`
  
  
This could be useful to gain insight on how engaging was the videos are, however, 
it is limited because there is no unique `learner_id` to link back to the other data 
frames such as `cyber.security.1_leaving.survey.responses` to perhaps determine 
that the video might not been that informative or understandable to the 
participant to complete (or even not that engaging to watch), or link it to the 
`cyber.security.1_step.activity` to determine how useful were the videos to be
able to pass the quizzes or tests in `cyber.security.1_question.response`.

### Verifying Data Quality: Data Quality Report 1

The data frame that is the most complete and could be most useful to infer an 
data insight to answer the 
[Newcastle University's success criteria](#determining-business-objectives-business-success-criteria-1) 
is `cyber.security.1_question.response` as it enables a way to identify 
participants' understanding of the course by answering questions from quizzes 
and tests. Thus, for now, the focus will be on it.

In this section, it first discusses the quality of the data types compare to the 
data its representing; second, it will discuss any missing or inconsistent 
data.

### I Data Quality Report - Data Types 1

Viewing the data types of each column in the data frame, it is divided in like 
the following:

```{r data_quality_cycle1, echo=FALSE}
data_types = as.data.frame(sapply(cyber.security.1_question.response, class))
data_types = data_types %>% rename("Data Types" = "sapply(cyber.security.1_question.response, class)")
knitr::kable(data_types, caption = "Data types of the columns from `cyber.security.1_question.response` dataset (excluded other runs, all of which have the same columns, for visualisation purposes)")
rm(data_types)
```

All of the columns, beside `submitted_at` and `correct`, should be the data type 
of factor. Factor is categorical (or commonly called in software development, 
enumerated type), which is more appropriate to these columns because the data is
attempting to be represented categorically:

  * `learner_id` - unique id to identify individual participants.
  
  * `quiz_question` - the quiz or test section number.
  
  * `question_type` - the type of the question.
  
  * `week_number` - the week of the online course (this will always be 1 up to 3
  because that is how long the online course duration takes)
  
  * `step_number` - the step number of the question in the section of the 
  `question_type`.
  
  * `question_number` - the individual question number in the `quiz_question`.
  
  * `response` - the chosen answers for the `question_number`.
  
The column `submitted_at` is representing the time the answer was submitted,
therefore,
the data type of character does not fully captures the data. Converting it 
to [POSIX date time](https://www.iso.org/iso-8601-date-and-time-format.html) 
will help to capture the time series of the data for data modelling and 
exploration.

For the column `correct`, even though the data type is represented as character, 
the only 2
sets of the data are "false" or "true", which is better represented as 
a logical data type.

```{r correct_column, echo=FALSE, message=FALSE, warning=FALSE}
run1_correct = cyber.security.1_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 1" = correct)
run2_correct = cyber.security.2_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 2" = correct)
run3_correct = cyber.security.3_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 3" = correct)
run4_correct = cyber.security.4_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 4" = correct)
run5_correct = cyber.security.5_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 5" = correct)
run6_correct = cyber.security.6_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 6" = correct)
run7_correct = cyber.security.7_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 7" = correct)

correct_df = bind_cols(run1_correct,
                       run2_correct,
                       run3_correct,
                       run4_correct,
                       run5_correct,
                       run6_correct,
                       run7_correct)

rm(run1_correct,
   run2_correct,
   run3_correct,
   run4_correct,
   run5_correct,
   run6_correct,
   run7_correct)

knitr::kable(correct_df, caption = "`correct` column only contains the values \"true\" and \"false\" ")
rm(correct_df)
```

Lastly, the column `cloze_response` is completely empty. Therefore, it cannot
be used and it does not seem to be as important as the rest of the data frame's
data.


```{r cloze_response, echo=FALSE, message=FALSE, warning=FALSE}
run1_clresponse = cyber.security.1_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 1" = cloze_response)
run2_clresponse = cyber.security.2_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 2" = cloze_response)
run3_clresponse = cyber.security.3_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 3" = cloze_response)
run4_clresponse = cyber.security.4_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 4" = cloze_response)
run5_clresponse = cyber.security.5_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 5" = cloze_response)
run6_clresponse = cyber.security.6_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 6" = cloze_response)
run7_clresponse = cyber.security.7_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 7" = cloze_response)

clresponse_df = bind_cols(run1_clresponse,
                       run2_clresponse,
                       run3_clresponse,
                       run4_clresponse,
                       run5_clresponse,
                       run6_clresponse,
                       run7_clresponse)

rm(run1_clresponse,
   run2_clresponse,
   run3_clresponse,
   run4_clresponse,
   run5_clresponse,
   run6_clresponse,
   run7_clresponse)

knitr::kable(clresponse_df, caption = "`cloze_response` column only contains `NA` values (`cloze_response` is abbreviated to `cl_response` for visualisation purposes)")
rm(clresponse_df)
```

### II Data Quality Report - Missing or Inconsistent Data 1 {#selecting-data-1}


```{r empty_learner_id_run1_example, echo=FALSE, message=FALSE, warning=FALSE}
# sprintf("Total of Empty `learner_id` for Run 1: %s", nrow(cyber.security.1_question.response %>% 
#   filter(learner_id == "") %>%
#   select(learner_id)))

knitr::kable(cyber.security.1_question.response %>% 
                 filter(learner_id == "") %>% 
                 select(-question_type, -cloze_response) %>%
                 rename("week_num"      = week_number,
                        "step_num"      = step_number,
                        "question_num"  = question_number) %>%
                 head(n = 4),
             caption = "Example of Run 1 containing empty `learner_id` values but still have values across the other columns (excludes `question_type`, `cloze_respond` and rest of the rows for visualisation purposes)")
```


In the column of `learner_id` there is missing data but yet it shows that those
empty has data in other columns. There is no simple solution to re-populate the
data, thus, due to the limited given time for this data mining project, the 
missing `learner_id` will be just removed.


```{r empty_learner_id_all_runs, echo=FALSE, message=FALSE, warning=FALSE}
run1_empty_id = cyber.security.1_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 1" = n)
run2_empty_id = cyber.security.2_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 2" = n)
run3_empty_id = cyber.security.3_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 3" = n)
run4_empty_id = cyber.security.4_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 4" = n)
run5_empty_id = cyber.security.5_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 5" = n)
run6_empty_id = cyber.security.6_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 6" = n)
run7_empty_id = cyber.security.7_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 7" = n)

empty_id_df = bind_cols(run1_empty_id,
                       run2_empty_id,
                       run3_empty_id,
                       run4_empty_id,
                       run5_empty_id,
                       run6_empty_id,
                       run7_empty_id)

rm(run1_empty_id,
   run2_empty_id,
   run3_empty_id,
   run4_empty_id,
   run5_empty_id,
   run6_empty_id,
   run7_empty_id)

knitr::kable(empty_id_df, caption = "Total of empty `learner_id` per run")
rm(empty_id_df)
```

Moreover, `learner_id` have duplicates on the same `quiz_question`. This is due
to participants attempting to submit new answers to the same questions. On 
the other hand, some individual `learner_id` have not completed all of the 
`quiz_question`.

```{r duplicates_and_incomplete, echo=FALSE}
example_run1_incomplete = cyber.security.1_question.response %>%
    select(learner_id, quiz_question, submitted_at) %>%
    filter(learner_id == "398a7b88-be48-4b29-9464-f41c7e475bfa")

all_quiz_question = cyber.security.1_question.response %>%
    select(quiz_question) %>%
    distinct() %>% 
    pull()

knitr::kable(example_run1_incomplete, caption = "An example of a `learner_id` in Run 1 with duplicates on the same `quiz_question` and not completed all the course `quiz_question` (excluded other columns for visualisation purposes)")

print("All of the `quiz_question` in Run 1")
print(all_quiz_question)

# knitr::kable(all_quiz_question, caption = "All of the `quiz_question` in Run 1")
rm(example_run1_incomplete, all_quiz_question)
```

A solution for the duplicates could be taking the assumption that the first 
submission of an individual `learner_id` is the honest attempt whereas the 
others are simply re-attempts to get the right answer. For the individual 
`learner_id` who have not attempting all of the `quiz_question`, removing those
`learner_id` as it is not complete overview of those participants performance, 
thus cannot be used for assessing the 
[success of the online courses](#determining-business-objectives-business-success-criteria-1)

## **Data Preparation 1**

### Dataset: Dataset Description 1

The datasets of focus will be on `question_response` for each run, 
that is `cyber.security.1_question.response` to 
`cyber.security.7_question.response`. As discuss in the 
[data quality section](#verifying-data-quality-data-quality-report-1), these are 
the most complete and most related to the [business' success criteria](#determining-business-objectives-business-success-criteria-1).

### Selecting Data: Rationale for inclusion / exclusion 1

The datasets all have the same columns, each column has been discussed under the
section [data quality report](#i-data-quality-report---data-types-1), however, 
the useful columns are the following:

* `learner_id` - to identify the participant for each of the question.
    
* `quiz_question` - to distinguish each question answered for each
    student.
    
* `week_number`, `step_number` and `question_number` - to subset the data to 
identify section, step number and question number for [modelling](#modelling-1).
    
* `correct` - to see if a participant has answered the question correctly
    or not.
    
These columns help to calculate a numerical census of the overall percentage of 
participants answering the question correctly or not. It can also help to 
find the lowest and highest percentages for questions answered correctly.

The rest of the columns are either redundant or not useful:
    
* `question_type` contains only one value which is "MultipleChoice".
    
* `response` are what the participants have choose as the answers, which is
    not particulary useful as `correct` shows if the answers are correct 
    anyways.
    
* `cloze_response` contain only the value `NA`
    
* `submitted_at` is not relevant as it only shows when the participant have
    submitted the question.
    
The changes are made under the file `munge/01-A.R`, the datasets are
going to be called `run1_qr` to `run1_qr` (`qr` stands for `question_response`).

### Cleaning Data: Data Cleaning Report 1

As discuss under the 
[data quality report](#ii-data-quality-report---missing-or-inconsistent-data-1) 
there are missing `learner_id` values which still contain values across the 
other columns. However, due to the time constraints for this data mining report,
the data would simply be deleted instead.

Furthermore, there are [duplicates and some individual `learner_id` who have not completed all of the `quiz_question`](#ii-data-quality-report---missing-or-inconsistent-data-1). To fix
that, remove duplicates by assuming that the first attempt is the honest attempt
and the others are re-attempts to get the right answer, then remove any 
`learner_id` individuals who have not completed all of course's `quiz_question`.

The changes are made under the files `munge/01-B.R` and `munge/02-A.R`.

### Integrating Data: Merged Data 1

There will be no merging data, as keeping the datasets separate for each run 
makes it easy to do analysis in the [modelling section](#modelling-1).

### Formating Data: Reformatted Data 1

After excluding the irrelevant columns, the rest of the columns 
data types are character types or numerical data types. 
`learner_id` and `quiz_question` data types will
be changed into factor data type as these columns are basically categorical data; 
for the `correct` as explained in 
[data quality report](#i-data-quality-report---data-types-1) only contains 
"false" and "true" thus it should reflect that by changing it to a logical 
data type.

```{r munge_qr, echo=FALSE}
before_data_reformatting = cyber.security.1_question.response %>% 
    select(-question_type, -response, -cloze_response, -submitted_at)
data_types = as.data.frame(sapply(before_data_reformatting, class))
data_types = data_types %>% rename("Data Types" = "sapply(before_data_reformatting, class)")
knitr::kable(data_types, caption = "Data types of the columns from `run1_qr` dataset before data reformatting (excluded other runs, all of which have the same columns, for visualisation purposes)")
rm(data_types, before_data_reformatting)
```

The changes are made under the file `munge/02-B.R`.

## Data Understanding - after data preprocessing

### Exploring Data 1

Exploring the datasets after data preprocessing has shown that the first run 
has the widest margin on total size of rows, totaling
`r format(run1_qr %>% nrow(), big.mark = ",")`. This can impact the 
accuracy of comparing runs to achieve [business' success criteria](#determining-business-objectives-business-success-criteria-1) as the 
first run has the most data, whereas the other course runs are more scarce 
compare to it - there more participants completing the course in run 1 rather
any other run.

```{r total_rows_per_run, echo=FALSE}
total_rows_per_run = data.frame(runs = c("Run 1",
                                           "Run 2",
                                           "Run 3",
                                           "Run 4",
                                           "Run 5",
                                           "Run 6",
                                           "Run 7"), 
                                total_rows = c(
                                    format(run1_qr %>% nrow(), big.mark = ","),
                                    format(run2_qr %>% nrow(), big.mark = ","),
                                    format(run3_qr %>% nrow(), big.mark = ","),
                                    format(run4_qr %>% nrow(), big.mark = ","),
                                    format(run5_qr %>% nrow(), big.mark = ","),
                                    format(run6_qr %>% nrow(), big.mark = ","),
                                    format(run7_qr %>% nrow(), big.mark = ",")
                                    ))
total_rows_per_run = total_rows_per_run %>%
    rename("Total rows of each run" = total_rows, "Course Runs" = runs)

knitr::kable(total_rows_per_run, caption = "Total rows of each run, `Run 1` is by far the largest out of all rows")
```

## **Modelling 1**

```{r cycle1_modelling, echo=FALSE, message=FALSE, warning=FALSE}
source("src/cycle1_modelling.R")
```

### Selecting Model Technique 1

Following the 
[business success criteria](#determining-business-objectives-business-success-criteria-1)
to represent the retrieved data after [data preparation](#data-preparation-1), a 
model of a barplot representing each run overall percentage of `correct` and 
`not correct` answers as stack bars can help to easily interpret the runs'
overall participants performance on understanding the material and answering 
the question corretly. In addition to the barplot, a lineplot is an option to 
see the line for the percentage of `correct` answers across course runs, helping
to answering the [success criteria "...has it improved over new runs of the
course?"](#determining-business-objectives-business-success-criteria)

### Building Models: Models and Models Descriptions 1

```{r barplot_with_lineplot_correct, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Percentage of 'Correct' and 'Not correct' answers for each course run"}
combined_bar_plot

quantile_crc = only_correct_runs %>% 
    select(percentage) %>% 
    pull() %>% 
    quantile() %>%
    t() 
    

knitr::kable(combined_runs_correct_2, caption = "Overiew of `correct` and `not correct` values in each run")
knitr::kable(quantile_crc, col.names = c("Min Correct",
           "Q1 Correct",
           "Average Correct",
           "Q3 Correct",
           "Max Correct") , caption = "Quantiles of `correct` answers on the entire course runs")
```
Figure 1 retrieves the overall total of all participants answers in each course
run and extracts the percentage of `correct` and `not correct` answers, then 
makes a stack bar plot. This results in an easier way to interpret course run
performance individually.

After that, the line plot on top of the barplot shows the trend of percentage 
of `correct` answers over the course runs. This helps to see visually if there 
the trend improving or worsening across course runs.

Table 9 is a summary table that accompanies Figure 1 by showing the exact values 
that is being represented in the figure, it is also show the number of total 
of `correct` and `not correct` answers made in each run.

Table 10 is the quantiles for percentage of `correct` answers for all of runs in
total. This helps to see the least, quartiles, average and largest values of 
the percentage of `correct`.

### Assessing Models 1

```{r metrics_correct, echo=FALSE, message=FALSE, warning=FALSE}
run2_percent = paste0(combined_runs_correct_2 %>% 
           filter(`Course Run` == "Run 2") %>% 
           pull(`Percentage of correct`), "%")
run6_percent = paste0(combined_runs_correct_2 %>% 
           filter(`Course Run` == "Run 6") %>% 
           pull(`Percentage of correct`), "%")
run1_2_increase = paste0("+", combined_runs_correct_2 %>%
    filter(`Course Run` == "Run 2") %>%
    pull(`Percentage of correct`) - combined_runs_correct_2 %>%
    filter(`Course Run` == "Run 1") %>%
    pull(`Percentage of correct`), "%")
run2_4_decrease = paste0(combined_runs_correct_2 %>%
    filter(`Course Run` == "Run 4") %>%
    pull(`Percentage of correct`) - combined_runs_correct_2 %>%
    filter(`Course Run` == "Run 2") %>%
    pull(`Percentage of correct`), "%")
run4_5_increase = paste0("+", combined_runs_correct_2 %>%
    filter(`Course Run` == "Run 5") %>%
    pull(`Percentage of correct`) - combined_runs_correct_2 %>%
    filter(`Course Run` == "Run 4") %>%
    pull(`Percentage of correct`), "%")
run5_7_decrease = paste0(combined_runs_correct_2 %>%
    filter(`Course Run` == "Run 7") %>%
    pull(`Percentage of correct`) - combined_runs_correct_2 %>%
    filter(`Course Run` == "Run 5") %>%
    pull(`Percentage of correct`), "%")
```

In Figure 1, the run with highest correct answers is "Run 2" with a 
`r run2_percent` whereas the lowest is "Run 6" with a `r run6_percent`. For the
lineplot the trend seem to fluctuate:

* "Run 1" to "Run 2" there is an increase of `r run1_2_increase` 

* "Run 2" to "Run 4" there is a continuous decrease of `r run2_4_decrease` 

* "Run 4" to "Run 5" there is an increase of `r run4_5_increase`

* "Run 5" to "Run 7" there is a slight continuous decrease of `r run5_7_decrease`


## **Evaluation 1**

### Evaluating Results 1

```{r metrics_overall, echo=FALSE, warning=FALSE, message=FALSE}
run1_rows_total = total_rows_per_run %>% filter(`Course Runs` == "Run 1") %>% pull(`Total rows of each run`)
run5_rows_total = total_rows_per_run %>% filter(`Course Runs` == "Run 5") %>% pull(`Total rows of each run`)
run4_rows_total = total_rows_per_run %>% filter(`Course Runs` == "Run 4") %>% pull(`Total rows of each run`)
```

Determining the most successful course run from dataset available, "Run 2" has the overall
best percentage of `correct` answers with `r run2_percent` and the least 
successful is "Run 6" with worst percentage of `correct` answers with
`r run6_percent`. However, as seen in the [exploring data](#exploring-data-1), 
after [data preparation](#data-preparation-1) where only the participants that
was retrieve are those who completed every `quiz_question` for each course run
to maintain an accurate and consistent dataset, it has costed the overall total
rows of data where "Run 1" has a total of `r run1_rows_total` compared to other
runs with much lower rows like `r run5_rows_total`. This effects the 
reliability of the dataset as the only run with a reasonable size of data is 
"Run 1" and perhaps "Run 4" with `r run4_rows_total`.

For finding if the course runs have improved overtime, it is the same idea where
the dataset for other course runs are significantly low to reach conclusion on,
but from the dataset available it would seem that there is not any improvements 
nor degradation as the percentage of `correct` fluctuate around the average 
mean of `r paste0(as.data.frame(quantile_crc) %>% pull("50%"),"%")`.

When considering this limited dataset, it would seem that the course is 
slightly successful with an average percentage of `correct` being `r paste0(as.data.frame(quantile_crc) %>% pull("50%"),"%")` showing that there more participants answering questions 
correctly than not. But as it is explained earlier, the dataset is limited to 
reach accurate conclusions.

### Determining Next Steps 1

To disregard this dataset that was made from 
[data preparation](#data-preparation) is going to be a waste, therefore, it is 
better solution to combine the course runs into one to determine other 
insights for the business needs. A possible route is determining for all the 
participants who have participated on answering all the questions in the courses
runs whether the having participants getting more `correct` answer encourages 
the participants to buy a certificate from the course or there is no 
correlation to it. This would help to give the business an insight to whether 
improve the course runs to help the understanding of the participants to 
successfully answer the question more `correctly` or rather even encourage 
more participants to answer all quizzes and test in the course to helps sales
on course certificates.


# Cycle 2

## **Business Understanding 2**

### Determining Business Objectives: Business Objectives 2

Following the [first cycle](#cycle-1), a better use of the data was to combine
the course runs into one to determine better insights. One solution, as 
mentioned in [determining next steps](#determining-next-steps-1) section, is to 
find correlation if the participants answering quizzes and tests more correctly
would encourage the participants to buy course certificates.

[FutureLearn](https://www.futurelearn.com/) is a company that might seek more
revenue through selling
certificates for the course, therefore, correlation on this can let the company
to focus more helping students understand the course better and encouraging
the participants to engage on answering quizzes and questions.

### Determining Business Objectives: Business Success Criteria 2

* "Is there a correlation where if participants are answering quizzes and tests
more correctly, it would likely encourage the participants to buy a 
course certificate?"

## **Data Understanding 2**

### Describing Data: Data Description Report 2

The [FutureLearn](https://www.futurelearn.com/) platform provides an option 
to purchase certificates from the online courses. The datasets that contains
any mention of purchase are `cyber.security.1_enrolments` to 
`cyber.security.7_enrolments`.

The most related columns are for the enrolments datasets:

* `learner_id` - unique id to identify individual participants.

* `purchased_statement_at` - date of purchase for a certificate.

### Exploring Data 2

```{r enrolments_data, echo=FALSE, message=FALSE, warning=FALSE}
combined_runs_enrolments = bind_rows(cyber.security.1_enrolments,
                                      cyber.security.2_enrolments,
                                      cyber.security.3_enrolments,
                                      cyber.security.4_enrolments,
                                      cyber.security.5_enrolments,
                                      cyber.security.6_enrolments,
                                      cyber.security.7_enrolments)

purchased_cert = data.frame(purchased_statement = combined_runs_enrolments %>% filter(purchased_statement_at != "") %>% nrow(),
                            not_purchased_statement = combined_runs_enrolments %>% filter(purchased_statement_at == "") %>% nrow()) %>%
    rename("Purchased Certificate" = purchased_statement,
           "Not Purchased Certificate" = not_purchased_statement)
knitr::kable(purchased_cert, caption = "Total participants who Purchased or Not Purchased Certificates")
```

Exploring the enrolments data column `purchased_statement_at`, there are
a total of `r combined_runs_enrolments %>% filter(purchased_statement_at != "") %>% nrow()`
out of `r combined_runs_enrolments %>% nrow()` participants who have purchased
a certificate.

### Verifying Data Quality: Data Quality Report 2

In this section of quality report, the enrolments dataset columns that will only
be covered is `learner_id` and `purchased_statement` as there are the most
related to the 
[business success](#determining-business-objectives-business-success-criteria-2). 

### I Data Quality Report - Data Types 2

```{r data_quality_cycle2, echo=FALSE, message=FALSE, warning=FALSE}
data_types_enrolment = as.data.frame(sapply(combined_runs_enrolments %>%
                                                select(learner_id, purchased_statement_at),
                                            class))
data_types_enrolment = data_types_enrolment %>% rename("Data Types" = "sapply(combined_runs_enrolments %>% select(learner_id, purchased_statement_at), class)")
knitr::kable(data_types_enrolment, caption = "Data types of `learner_id` and `purchased_statement_at` columns from the enrolments dataset")
```

Both columns of `learner_id` and `purchased_statement_at` are data types of 
character, which is does not fit the values those columns contain.

* `learner_id` - more of a categorical data, it contains special unique 
ids' for each participants.

* `purchased_statement_at`  - it is showing a [POSIX date time](https://www.iso.org/iso-8601-date-and-time-format.html), therefore, it is
convert to POSIX standard to capture the time series data,


### II Data Quality Report - Missing or Inconsistent Data 2

There is no significant missing data nor inconsistent data in the 
enrolments dataset to be found that effects the 
[business success criteria](#determining-business-objectives-business-success-criteria-2).

## **Data Preparation 2**

[As established earlier](#data-understanding-2), 
the enrolment dataset of `cyber.security.1_enrolments` 
to `cyber.security.7_enrolments` is the most applicable to the 
cycle 2 
[business success criteria](#determining-business-objectives-business-success-criteria-2)
of finding the correlation of purchased certificate with question being 
answered correctly.

### Integrating Data: Merged Data 2-1

Stepping ahead of [selecting data](#selecting-data-2), it is better to merge the enrolment data
into one from now on to make the other steps of 
[data preparation](#data-preparation) easier to process. The reason to merge 
the course runs into one big dataset is that the 
[success ceriteria](#determining-business-objectives-business-success-criteria)
is focused on the overall runs to find if there is correlation between 
participants purchasing a certificate and answering question correctly.

The changes are made under the file `munge/03-A.R`.

### Selecting Data: Rationale for inclusion / exclusion 2 {#selecting-data-2}

As explained under [data understanding](#data-understanding-2), the most
relevant columns in the enrolment dataset are:

* `learner_id` - to identify individual participant.

* `purchased_statement_at` - to see if the participant have purchased a 
certificate or not.

The changes are made under the file `munge/03-AA.R`.

### Cleaning Data: Data Cleaning Report 2

Under the 
[data quality](#ii-data-quality-report---missing-or-inconsistent-data-2) 
section, there were no missing or inconsistent
data on the enrolment dataset that could effect the 
[success criteria](#determining-business-objectives-business-success-criteria-2).

### Formating Data: Reformatted Data 2

Before discussing how and why merge the data of enrolment dataset to the 
cycle 1 `run1_qr` and `run7_qr`, it is first important to update the data types
of the enrolment data type to avoid issues when merging.

* `learner_id` - convert from character type to factor type as it representing
a categorical data of unique ids that identify each individual participants.

* `purchased_statement_at` - convert from character type to a logical type. This
would seem a bit strange as the values seem to be representing 
[POSIX date time](https://www.iso.org/iso-8601-date-and-time-format.html)
values, however, the 
[success criteria](#determining-business-objectives-business-success-criteria-2)
only cares about if the participants have purchased certificates or not 
thus any empty string will be converted to the value `FALSE` otherwise `TRUE`.
Furthermore, renaming `purchase_certificate` will help explain what the 
column is for and also better fit the new logical data type.

The changes are made under the file `munge/03-B.R`.

### Integrating Data: Merged Data 2-2

From the [determining next steps](#determining-next-steps-1) section ideas, a 
merging of dataset for `run1_qr` to `run7_qr` to the enrolment dataset 
helps to narrow the dataset to only assess the participants who have 
answered every questions step during the course entire runs and find if there
is any correlation of participants who have answered correctly would more 
likely purchase a certificate. 

The changes are made under the file `munge/03-C.R` - the merged dataset is going
to be called `merged_enrolment_data`.

## **Modelling 2**

```{r cycle2_modelling, echo=FALSE, warning=FALSE, message=FALSE}
source("src/cycle2_modelling.R")
```

### Selecting Model Technique 2

```{r modelling_techniq, echo=FALSE, warning=FALSE, message=FALSE}
merged_colnames = paste0("`", merged_enrolment_data %>% colnames(), "`")
merged_data_type_model = paste0("`", merged_enrolment_data %>%
                              select(purchase_certificate, correct) %>%
                              pull() %>%
                              class(),
                          "`")
```

After the [data preparation](#data-preparation-2), the `merged_enrolment_data` 
columns are `r merged_colnames`. As [explained earlier](#data-understanding), 
the most relevant columns to are `learner_id` and `purchase_certificate` but 
[also `correct`](#integrating-data-merged-data-2-2) to answer the 
[business success criteria](#determining-business-objectives-business-success-criteria-2).
These are the columns that represent if each individual participant have 
purchased a certificate and if the answered question correctly in the course
quizzes and tests.

Therefore, a model should plot each `learner_id` against axis 
of `purchased_certiifcate` and `correct` columns. However, the both 
`purchased_certificate` and `correct` columns are `r merged_data_type_model`, 
meaning that it cannot simply be represented as scatterplot to investigate
a correlation. 

A solution is to create a heatmap that has axis values of 
`TRUE` or `FALSE` for these columns to `learner_id` against it. This will 
provided the insight to see if the individual participants that answers 
questions correctly will likely purchase a certificate.

```{r enrol_dataset_sample, echo=FALSE, warning=FALSE, message=FALSE}
knitr::kable(merged_enrolment_data %>%
                 select(-week_number,
                        -step_number,
                        -question_number) %>%
                 head(n = 5), caption = "Sample of `merged_enrolment_data` dataset (excluded `week_number`, `step_number` and `question_number` for visualisation purposes)")
```

### Building Models: Models and Models Descriptions 2

Figure 2 is a heatmap representing the distribution of individual participants
against values of the logical type of `FALSE` and `TRUE`. Each cell in the 
heatmap represents a combination of a participant's purchase certificate status 
and whether their answer was correct. The colour of each cell is determined by 
the number of participants falling into that combination. 

The color intensity in each cell indicates the count of participants for a 
specific combination of purchase certificate and answer correctness. A gradient 
from light gray to dark blue is used, where darker shades represent higher 
participant counts.

Table 9 provides a clear and organised view of the participant counts for 
different combinations of purchase certificate status and answer correctness. 
Each row in the table corresponds to a unique combination, and the 
"Participants Count" column displays the count of participants in a 
human-readable format with commas as thousand separators. This summary 
facilitates easy interpretation and comparison of participant distribution 
across various categories.

```{r heatmap_plot, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Heatmap for Purchase Certificate against Answer Correct"}
heatmap_enrol

knitr::kable(summary_of_heatmap_enrol, caption = "Summary of heatmap figure")
```

### Assessing Models 2

```{r summary_enrol, warning=FALSE, message=FALSE, echo=FALSE}
false_true_correct = summary_of_heatmap_enrol %>% 
    filter(`Purchase Certificate` == FALSE & `Answer Correct` == TRUE) %>%
    pull(`Participants Count`)
false_false_correct = summary_of_heatmap_enrol %>% 
    filter(`Purchase Certificate` == FALSE & `Answer Correct` == FALSE) %>%
    pull(`Participants Count`)
true_true_correct = summary_of_heatmap_enrol %>% 
    filter(`Purchase Certificate` == TRUE & `Answer Correct` == TRUE) %>%
    pull(`Participants Count`)
true_false_correct = summary_of_heatmap_enrol %>% 
    filter(`Purchase Certificate` == TRUE & `Answer Correct` == FALSE) %>%
    pull(`Participants Count`)
```

Figure 1 shows high concentration of participants have not purchased a 
certificate compared to those who have. It that there is an even 
divide between of the participants answer correctness for each combination 
of purchase certificate status:

* Purchase status `FALSE` have the division of `r false_true_correct` and 
`r false_false_correct` for answers correctly or not respectively.

* Purchase status `TRUE` have the division of `r true_true_correct` and 
`r true_false_correct` for answers correctly or not respectively.

## **Evaluation 2**

### Evaluating Results 2

The analysis of the data, as visualised in Figure 1, reinforces the conclusion 
that there is no significant correlation between participants' purchase 
certificate status and their answer correctness. The heatmap illustrates the 
distribution of participants, highlighting the absence of a pronounced pattern 
indicating a relationship between these two variables.

Figure 1 depicts a high concentration of participants who have not purchased a 
certificate compared to those who have. The heatmap shows an even divide between
participants' answer correctness for each combination of purchase certificate 
status:

* For participants with a purchase status of 'FALSE', the heatmap indicates 
19,193 instances of incorrect answers and 16,645 instances of correct answers.

* For participants with a purchase status of 'TRUE', the heatmap shows 2,544 
instances of incorrect answers and 1,680 instances of correct answers.

The heatmap's visual representation aligns with the numeric division, further 
supporting the conclusion that there is no discernible correlation. Participants
who answer quizzes and tests more correctly do not exhibit a clear tendency to 
purchase a course certificate.

In summary, the heatmap reinforces the analysis, suggesting that answer 
correctness does not serve as a strong predictor for participants' likelihood to
purchase a certificate. The absence of a distinct pattern in the heatmap 
indicates that additional factors or variables may need to be considered to 
better understand the factors influencing participants' decisions to purchase 
certificates.

## **Deployment 2**

### Final Report: Summary 2

...

### Final Report: Deploying a Presentation

...

