---
title: 'CSC8631 Project: Learning Anaylitcs'
author: "Abdullah Turki H Alshadadi, 190582184"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath(".."))
```

``` {r ProjectTemplate, include=FALSE}
library(ProjectTemplate)
load.project()
```

## Introduction

This report is a data mining report exploring the online course of 
"Cybersecurity: Safety At Home, Online, and in life" - which was created by 
[Newcastle University](https://www.ncl.ac.uk) published in 
[FutureLearn](https://www.futurelearn.com/) educational platform.

It will be structured in the method of CRISP-DM (Cross-Industry Standard 
Process for Data Mining), where it will discuss the Business Understanding,
Data Understanding, Data Preparation, Modelling, Evaluation and Deployment 
from the given data.

Due to following the CRISP-DM, there will be cycles around the previously 
discussed headings because of better built understanding of the business 
intentions with the current focused data that needs more insight, or because 
limitation of data to meet the business needs, or even because of a better 
understanding on the data that shows significant importance to the business 
that the business intentions are changed to meet align more to the data.


# Cycle 1

## **Business Understanding**

### Determining Business Objectives: Background

This online course is about the discipline Cybersecurity made by 
Newcastle University, a high education provider that seeks to make the course 
publicly accessible by individuals through the educational online platform 
FutureLearn.

FutureLearn provides the platform to host the online course with the benefit
of providing Newcastle University with learning data of participating 
individuals on their course.

Using the provided raw data from FutureLearn, Newcastle University will likely 
want to derive insights on how "successful" is the learning design of the 
course, did most individuals pass the online course and did it increase over
the life time of the course?


### Determining Business Objectives: Business Objectives

FutureLearn's raw data of the online course needs insights to be able to quantify
measurements of participating individuals engagement on the course for Newcastle
University.

Through data analysis, Newcastle University will likely want to know the 
how "successful" is the engagement of the course, in terms whether the
the participants have pass or not. This is important 
because it will show the effectiveness of their course and determine the 
best run in the online course.

### Determining Business Objectives: Business Success Criteria

The following is the possible success criteria of Newcastle University:

* "How successful was the online course; has it improved over new runs of the
course?"
  
### Assessing Situation: Inventory of Resources

The given data is 7 runs of the online course from September 2016 to
February 2018, where it is not expected to have more data from the 
FutureLearn as [currently Newcastle University stopped the online course](https://www.futurelearn.com/courses/cyber-security).
Therefore, management of resources are much easier and manageable as the only
data to be concern with is the provided 7 runs data.


### Assessing Situation: Requirements, assumptions, and constraints

For requirements, there is a deadline of submission for
this report, limiting the chance of deep data exploration. Thus, the report will 
focus on the basic vital needs to meet the [Newcastle Univesity's success criteria](#determining-business-objectives-business-success-criteria).

For assumptions, the models for the data should be presented in way where it can
show trends and variance in the data, so that it will be possible to explain to
a novice statistician or user from Newcastle University's online course 
designers' to understand the success of their course while retaining solid 
statistical foundation.


Lastly, there is no constraints on the use of the given raw data
from FutureLearn, but the only issue is that this is the only data that will be
provided.


### Assessing Situation: Risks and Contingencies

There is the risk of data not showing results of that convey passed or failed 
participants, but rather show other factors such as the participants 
satisfaction or engagement in the sense that they have partaken 
in the activities of the course. For that, the plan is to adjust to these 
types of data factors and readjust the 
[Newcastle University's success criteria](#determining-business-objectives-business-success-criteria) to reflect
better to the data and the [business needs](#determining-business-objectives-business-objectives).

Furthermore, there is risk of the data to be lost or corrupted, thus a backup is
made for the data away from the [ProjectTemplate](http://projecttemplate.net/)
`data` folder just in case if a mistake is made, and everything is stored in 
the cloud by [OneDrive](https://www.microsoft.com/en-gb/microsoft-365/onedrive/online-cloud-storage) provided by Newcastle University.


### Assessing Situation: Terminology

There is no set of business terminologies to be aware of, therefore, there 
should not be any special terms that contain exclusive meanings in the data by
Newcastle University or FutureLearn.


### Assessing Situation: Cost and Benefits

There is no cost on this project, in terms of financial cost but instead it is a 
workflow cost, where this data mining project is heavily limited by time.
However, the benefits are that Newcastle University would have a better 
understanding on the performance of their online course.


### Determining Data Mining Goals: Data Mining Goals

Gain insights on the data to determine what constitutes as "success" in the 
online course by concept description and classify those who have passed or 
those who have not passed.


### Determining Data Mining Goals: Data Mining Success Criteria

Models that can identify the percentage of passed or not passed participants 
using the "success" data to show and view the change of "success" over the 7 runs 
of the course to see if it has decreasing over time or not, and what run was
that has the most "success". 
This would likely help to show how effective is the course 
for Newcastle University over the span of 7 runs and identify the best run in
the online course.


## **Data Understanding**

### Describing Data: Data Description Report

Before describing the data, there is the need to describe how the online
course is structured. The online course duration is 3 weeks, therefore it 
consists of 3 main sections which are "Exploring personal privacy online", 
"Online payment security" and "Security in the future home".

Within each section, there is what the Newcastle University and FutureLearn 
called "steps", which is the main subsection activities to do in the 
online course, and it also contains a "step number" that shows the participant 
the total activities to do per sections.

These step activities are catogrise into ARTICLE, DISCUSSION, EXERCISE, QUIZ,
TEST and VIDEO.

For first run, it is structured like so:

  * Section 1 "Exploring personal privacy online"
    * Steps 1.1 to 1.18, which has the step number of 18
    * It contains 9 ARTICLE, 2 DISCUSSION, 1 EXCERCISE, 1 QUIZ and 5 VIDEO
    
  * Section 2 "Online payment security"
    * Steps 2.1 to 2.21, which has the step number of 21
    * It contains 13 ARTICLE, 2 DISCUSSION, 1 EXCERCISE, 2 QUIZ and 3 VIDEO
    
  * Section 3 "Security in the future home"
    * Steps 3.1 to 3.21, which has the step number of 21
    * It contains 10 ARTICLE, 4 DISCUSSION, 1 EXCERCISE, 1 QUIZ, 1 TEST and 
    4 VIDEO
    
For the second run, there are steps been added to Section 2 and Section 3:

  * Section 1 "Exploring personal privacy online"
    * Step 1.2 "Why are you here? DISCUSSION" is the new step, making the steps
    number to become 19, which means the steps are 1.1 to 1.19
    * It added 1 ARTICLE
    
  * Section 2 "Online payment security"
    * Step 2.11 "Exploring vulnerabilities in online payments VIDEO (05:12)" 
    and step 2.22 "Auditing your Mobile App permissions ARTICLE" are the new 
    step, making the steps number to become 23, which means the steps are 2.1 
    to 1.22
    * It added 1 ARTICLE and 1 VIDEO
    
Then for the third run a step has been removed:

  * Section 3 "Security in the future home"
    * Step 3.21 "Glossary and references ARTICLE" is the removed step, making 
    the steps number to become 20, which means the steps are 3.1 to 3.21
    * It removed 1 ARTICLE

After understanding the online course terminology, the description of data will
be discussed.

For the first run of the online course, the data from FutureLearn is split into 
6 data frames:

  1. `cyber.security.1_archetype.survey.responses`
  
  2. `cyber.security.1_enrolments`
  
  3. `cyber.security.1_leaving.survey.responses`
  
  4. `cyber.security.1_question.response`
  
  5. `cyber.security.1_step.activity`
  
  6. `cyber.security.1_weekly.sentiment.survey.responses`
  
  
Then in the second run of the online course, the data from FutureLearn has 
expanded to include:

  7. `cyber.security.2_team.members`
  
Lastly, the third run of the online course, the data from FutureLearn has 
once more expanded to include:

  8. `cyber.security.3_video.stats`

  
#### 1.

Archetypes are list of categorical data that describes the behaviour and 
personality of the participants of the course, and these archetypes are 
Advancers, Explorers, Fixers, Flourishers, Hobbyists, Preparers and Vitalisers
(there is also the options to pick Other).

However, this data set would unlikely be useful as it shows personal character
traits which is more appropriate for marketing purpose especially if the 
business (that is Newcastle University) would like to have more participants
to the course it would target archetypes of users - with more supporting data - 
that has the most engagement (for example, successfully completing the whole 
course) to market for.

In contrast, from [Business Understanding section](#business-understanding), 
Newcastle University would prefer to understand if their online course was 
simply "successful", in the sense that the participants have passed the online
course, on the 7 runs of the course.

#### 2.

The data set that keeps track of the participants of the online course. Where 
the most interesting columns are `learner_id` that 
provides a unique code for referencing individual participants 
and `fully_participated_at` that verify that a participant have fully 
completed the course.

#### 3.

Data set that includes participants that have left the course without 
completing it. It contains data that verifies the time the participants have
left, their reasoning, last completed step in the course, last completed week of
the course and last completed step number.

This could be useful for another in depth analysis to pinpoint why did the 
participant not complete the course and what step or step number they were 
in before they left, to infer need of improvements for the sections that has 
the most leaving response.

#### 4.

This data keeps track of the quiz or test subsections responses from
participants in the online course. It shows what step number the quiz or 
test was that might be useful to link it back to the leaving response to 
figure out if the quiz and test were the discouraging problem that participants
had, or link it back to the step activity that keeps track on the step the 
participants have done which is useful to determine why some participants have 
performed better than others.

It also contains a column, `correct`, which shows if the participant have 
answered the question of a quiz or test correctly or not. This is especially 
useful to determine the total passed participants in the course to meet 
[Newcastle University's success criteria](#determining-business-objectives-business-success-criteria).

#### 5.

For this data, it keeps track of what step activity of the online course is the
participant is in, when did the participant started it and when did the 
participant have finished the step activity.

This could also be useful to keep track of the engagement the participants and 
can be useful to also link it back to the leave response to determine what was
the most discouraging section out of the online course.

#### 6.

This data keeps track of the weekly responses on the online course to determine
the participants experience for what week section there are in. It contains 
rating system, called `experience_rating`, and a response, `reason`, of the 
picked rating system.

#### 7.

This data lacks enough information to understand what is trying to represent. 
An educated guess that it could be for representing the Newcastle University 
staff who keeps track of the online course and perhaps questions or feedback
from the participants. This is because in the column `team_role` it 
classifies the individuals in the data frame as `host`, `lead_educator`,
`educator`, `mentor`, `reviewer` and `facilitator`.

#### 8.

This data keeps track of the video statistics. It contains a lot of 
informative numerical statistics about the videos.

It shows the videos duration in the online course in seconds - this was verified 
by document image shot provided by Newcastle University of how the online course 
looked like, for example the first video in the online course contains the 
number format of "01:39" which is usually representing "minutes:seconds", and 
1 minute and 39 seconds in seconds are in total 99 seconds.

From the other stats, the most interesting are the following:

  * `total_views`
  
  * `viewed_five_percent`
  
  * `viewed_ten_percent`
  
  * `viewed_twentyfive_percent`
  
  * `viewed_fifty_percent`
  
  * `viewed_seventyfive_percent`
  
  * `viewed_ninetyfive_percent`
  
  * `viewed_onehundred_percent`
  
  
This could be useful to gain insight on how engaging was the videos are, however, 
it is limited because there is no unique `learner_id` to link back to the other data 
frames such as `cyber.security.1_leaving.survey.responses` to perhaps determine 
that the video might not been that informative or understandable to the 
participant to complete (or even not that engaging to watch), or link it to the 
`cyber.security.1_step.activity` to determine how useful were the videos to be
able to pass the quizzes or tests in `cyber.security.1_question.response`.

### Verifying Data Quality: Data Quality Report

The data frame that is the most complete and could be most useful to infer an 
data insight to answer the 
[Newcastle University's success criteria](#determining-business-objectives-business-success-criteria) 
is `cyber.security.1_question.response` as it enables a way to identify 
participants' understanding of the course by answering questions from quizzes 
and tests. Thus, for now, the focus will be on it.

In this section, it first discusses the quality of the data types compare to the 
data its representing; second, it will discuss any missing or inconsistent 
data.

### I Data Quality Report - Data Types

Viewing the data types of each column in the data frame, it is divided in like 
the following:

```{r echo=FALSE}
data_types = as.data.frame(sapply(cyber.security.1_question.response, class))
data_types = data_types %>% rename("Data Types" = "sapply(cyber.security.1_question.response, class)")
knitr::kable(data_types, caption = "Data types of the columns from `cyber.security.1_question.response` dataset (excluded other runs, all of which have the same columns, for visualisation purposes)")
rm(data_types)
```

All of the columns, beside `submitted_at` and `correct`, should be the data type 
of factor. Factor is categorical (or commonly called in software development, 
enumerated type), which is more appropriate to these columns because the data is
attempting to be represented categorically:

  * `learner_id` - unique id to identify individual participants.
  
  * `quiz_question` - the quiz or test section number.
  
  * `question_type` - the type of the question.
  
  * `week_number` - the week of the online course (this will always be 1 up to 3
  because that is how long the online course duration takes)
  
  * `step_number` - the step number of the question in the section of the 
  `question_type`.
  
  * `question_number` - the individual question number in the `quiz_question`.
  
  * `response` - the chosen answers for the `question_number`.
  
The column `submitted_at` is representing the time the answer was submitted,
therefore,
the data type of character does not fully captures the data. Converting it 
to [POSIX date time](https://www.iso.org/iso-8601-date-and-time-format.html) 
will help to capture the time series of the data for data modelling and 
exploration.

For the column `correct`, even though the data type is represented as character, 
the only 2
sets of the data are "false" or "true", which is better represented as 
a logical data type.

```{r correct_column, echo=FALSE, message=FALSE, warning=FALSE}
run1_correct = cyber.security.1_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 1" = correct)
run2_correct = cyber.security.2_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 2" = correct)
run3_correct = cyber.security.3_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 3" = correct)
run4_correct = cyber.security.4_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 4" = correct)
run5_correct = cyber.security.5_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 5" = correct)
run6_correct = cyber.security.6_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 6" = correct)
run7_correct = cyber.security.7_question.response %>% select(correct) %>%
    distinct() %>% rename("`correct` column values for Run 7" = correct)

correct_df = bind_cols(run1_correct,
                       run2_correct,
                       run3_correct,
                       run4_correct,
                       run5_correct,
                       run6_correct,
                       run7_correct)

rm(run1_correct,
   run2_correct,
   run3_correct,
   run4_correct,
   run5_correct,
   run6_correct,
   run7_correct)

knitr::kable(correct_df, caption = "`correct` column only contains the values \"true\" and \"false\" ")
rm(correct_df)
```

Lastly, the column `cloze_response` is completely empty. Therefore, it cannot
be used and it does not seem to be as important as the rest of the data frame's
data.


```{r cloze_response, echo=FALSE, message=FALSE, warning=FALSE}
run1_clresponse = cyber.security.1_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 1" = cloze_response)
run2_clresponse = cyber.security.2_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 2" = cloze_response)
run3_clresponse = cyber.security.3_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 3" = cloze_response)
run4_clresponse = cyber.security.4_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 4" = cloze_response)
run5_clresponse = cyber.security.5_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 5" = cloze_response)
run6_clresponse = cyber.security.6_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 6" = cloze_response)
run7_clresponse = cyber.security.7_question.response %>% select(cloze_response) %>%
    distinct() %>% rename("`cl_response` column values for Run 7" = cloze_response)

clresponse_df = bind_cols(run1_clresponse,
                       run2_clresponse,
                       run3_clresponse,
                       run4_clresponse,
                       run5_clresponse,
                       run6_clresponse,
                       run7_clresponse)

rm(run1_clresponse,
   run2_clresponse,
   run3_clresponse,
   run4_clresponse,
   run5_clresponse,
   run6_clresponse,
   run7_clresponse)

knitr::kable(clresponse_df, caption = "`cloze_response` column only contains `NA` values (`cloze_response` is abbreviated to `cl_response` for visualisation purposes)")
rm(clresponse_df)
```

### II Data Quality Report - Missing or Inconsistent Data


```{r empty_learner_id_run1_example, echo=FALSE, message=FALSE, warning=FALSE}
# sprintf("Total of Empty `learner_id` for Run 1: %s", nrow(cyber.security.1_question.response %>% 
#   filter(learner_id == "") %>%
#   select(learner_id)))

knitr::kable(cyber.security.1_question.response %>% 
                 filter(learner_id == "") %>% 
                 select(-question_type, -cloze_response) %>%
                 rename("week_num"      = week_number,
                        "step_num"      = step_number,
                        "question_num"  = question_number) %>%
                 head(n = 4),
             caption = "Example of Run 1 containing empty `learner_id` values but still have values across the other columns (excludes `question_type`, `cloze_respond` and rest of the rows for visualisation purposes)")
```


In the column of `learner_id` there is missing data but yet it shows that those
empty has data in other columns. There is no simple solution to re-populate the
data, thus, due to the limited given time for this data mining project, the 
missing `learner_id` will be just removed.


```{r empty_learner_id_all_runs, echo=FALSE, message=FALSE, warning=FALSE}
run1_empty_id = cyber.security.1_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 1" = n)
run2_empty_id = cyber.security.2_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 2" = n)
run3_empty_id = cyber.security.3_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 3" = n)
run4_empty_id = cyber.security.4_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 4" = n)
run5_empty_id = cyber.security.5_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 5" = n)
run6_empty_id = cyber.security.6_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 6" = n)
run7_empty_id = cyber.security.7_question.response %>% select(learner_id) %>%
    filter(learner_id == "") %>% count() %>% 
    select(n) %>% rename("Total number of empty `learner_id` in Run 7" = n)

empty_id_df = bind_cols(run1_empty_id,
                       run2_empty_id,
                       run3_empty_id,
                       run4_empty_id,
                       run5_empty_id,
                       run6_empty_id,
                       run7_empty_id)

rm(run1_empty_id,
   run2_empty_id,
   run3_empty_id,
   run4_empty_id,
   run5_empty_id,
   run6_empty_id,
   run7_empty_id)

knitr::kable(empty_id_df, caption = "Total of empty `learner_id` per run")
rm(empty_id_df)
```

Moreover, `learner_id` have duplicates on the same `quiz_question`. This is due
to participants attempting to submit new answers to the same questions. On 
the other hand, some individual `learner_id` have not completed all of the 
`quiz_question`.

```{r duplicates_and_incomplete, echo=FALSE}
example_run1_incomplete = cyber.security.1_question.response %>%
    select(learner_id, quiz_question, submitted_at) %>%
    filter(learner_id == "398a7b88-be48-4b29-9464-f41c7e475bfa")

all_quiz_question = cyber.security.1_question.response %>%
    select(quiz_question) %>%
    distinct() %>% 
    pull()

knitr::kable(example_run1_incomplete, caption = "An example of a `learner_id` in Run 1 with duplicates on the same `quiz_question` and not completed all the course `quiz_question` (excluded other columns for visualisation purposes)")

print("All of the `quiz_question` in Run 1")
print(all_quiz_question)

# knitr::kable(all_quiz_question, caption = "All of the `quiz_question` in Run 1")
rm(example_run1_incomplete, all_quiz_question)
```

A solution for the duplicates could be taking the assumption that the first 
submission of an individual `learner_id` is the honest attempt whereas the 
others are simply re-attempts to get the right answer. For the individual 
`learner_id` who have not attempting all of the `quiz_question`, removing those
`learner_id` as it is not complete overview of those participants performance, 
thus cannot be used for assessing the 
[success of the online courses](#determining-business-objectives-business-success-criteria)

## **Data Preparation**

### Dataset: Dataset Description

The datasets of focus will be on `question_response` for each run, 
that is `cyber.security.1_question.response` to 
`cyber.security.7_question.response`. As discuss in the 
[data quality section](#verifying-data-quality-data-quality-report), these are 
the most complete and most related to the [business' success criteria](#determining-business-objectives-business-success-criteria).

### Selecting Data: Rationale for inclusion / exclusion

The datasets all have the same columns, each column has been discussed under the
section [data quality report](#i-data-quality-report---data-types), however, 
the useful columns are the following:

* `learner_id` - to identify the participant for each of the question.
    
* `quiz_question` - to distinguish each question answered for each
    student.
    
* `week_number`, `step_number` and `question_number` - to subset the data to 
identify section, step number and question number for [modelling](#modelling).
    
* `correct` - to see if a participant has answered the question correctly
    or not.
    
These columns help to calculate a numerical census of the overall percentage of 
participants answering the question correctly or not. It can also help to 
find the lowest and highest percentages for questions answered correctly.

The rest of the columns are either redundant or not useful:
    
* `question_type` contains only one value which is "MultipleChoice".
    
* `response` are what the participants have choose as the answers, which is
    not particulary useful as `correct` shows if the answers are correct 
    anyways.
    
* `cloze_response` contain only the value `NA`
    
* `submitted_at` is not relevant as it only shows when the participant have
    submitted the question.
    
The changes are made under the file `munge/01-A.R`, the datasets are
going to be called `run1_qr` to `run1_qr` (`qr` stands for `question_response`).

### Cleaning Data: Data Cleaning Report

As discuss under the 
[data quality report](#ii-data-quality-report---missing-or-inconsistent-data) 
there are missing `learner_id` values which still contain values across the 
other columns. However, due to the time constraints for this data mining report,
the data would simply be deleted instead.

Furthermore, there are [duplicates and some individual `learner_id` who have not completed all of the `quiz_question`](#ii-data-quality-report---missing-or-inconsistent-data). To fix
that, remove duplicates by assuming that the first attempt is the honest attempt
and the others are re-attempts to get the right answer, then remove any 
`learner_id` individuals who have not completed all of course's `quiz_question`.

The changes are made under the files `munge/01-B.R` and `munge/02-A.R`.

### Integrating Data: Merged Data

There will be no merging data, as keeping the datasets separate for each run 
makes it easy to do analysis in the [modelling section](#modelling).

### Formating Data: Reformatted Data

After excluding the irrelevant columns, the rest of the columns 
data types are character types or numerical data types. 
`learner_id` and `quiz_question` data types will
be changed into factor data type as these columns are basically categorical data; 
for the `correct` as explained in 
[data quality report](#i-data-quality-report---data-types) only contains 
"false" and "true" thus it should reflect that by changing it to a logical 
data type.

```{r munge_qr, echo=FALSE}
before_data_reformatting = cyber.security.1_question.response %>% 
    select(-question_type, -response, -cloze_response, -submitted_at)
data_types = as.data.frame(sapply(before_data_reformatting, class))
data_types = data_types %>% rename("Data Types" = "sapply(before_data_reformatting, class)")
knitr::kable(data_types, caption = "Data types of the columns from `run1_qr` dataset before data reformatting (excluded other runs, all of which have the same columns, for visualisation purposes)")
rm(data_types, before_data_reformatting)
```

The changes are made under the file `munge/02-B.R`.

## Data understanding - after data preprocessing

### Exploring data

Exploring the datasets after data preprocessing has shown that the first run 
has the widest margin on total size of rows, totaling
`r format(run1_qr %>% nrow(), big.mark = ",")`. This can impact the 
accuracy of comparing runs to achieve [business' success criteria](#determining-business-objectives-business-success-criteria) as the 
first run has the most data, whereas the other course runs are more scarce 
compare to it - there more participants completing the course in run 1 rather
any other run.

```{r total_rows_per_run, echo=FALSE}
total_rows_per_run = data.frame(runs = c("Run 1",
                                           "Run 2",
                                           "Run 3",
                                           "Run 4",
                                           "Run 5",
                                           "Run 6",
                                           "Run 7"), 
                                total_rows = c(
                                    format(run1_qr %>% nrow(), big.mark = ","),
                                    format(run2_qr %>% nrow(), big.mark = ","),
                                    format(run3_qr %>% nrow(), big.mark = ","),
                                    format(run4_qr %>% nrow(), big.mark = ","),
                                    format(run5_qr %>% nrow(), big.mark = ","),
                                    format(run6_qr %>% nrow(), big.mark = ","),
                                    format(run7_qr %>% nrow(), big.mark = ",")
                                    ))
total_rows_per_run = total_rows_per_run %>%
    rename("Total rows of each run" = total_rows, "Course Runs" = runs)

knitr::kable(total_rows_per_run, caption = "Total rows of each run, `Run 1` is by far the largest out of all rows")
rm(total_rows_per_run)
```

## **Modelling**

```{r cycle1_modelling, echo=FALSE, message=FALSE, warning=FALSE}
source("src/cycle1_modelling.R")
```

### Selecting model technique

Following the 
[business success criteria](#determining-business-objectives-business-success-criteria)
to represent the retrieved data after [data preparation](#data-preparation), a 
model of a barplot representing each run overall percentage of `correct` and 
`not correct` answers as stack bars can help to easily interpret the runs'
overall participants performance on understanding the material and answering 
the question corretly. In addition to the barplot, a lineplot is an option to 
see the line for the percentage of `correct` answers across course runs, helping
to answering the [success criteria "...has it improved over new runs of the
course?"](#determining-business-objectives-business-success-criteria)

### Building models: models and models descriptions

```{r barplot_with_lineplot_correct, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Percentage of 'Correct' and 'Not correct' answers for each course run"}
combined_bar_plot

quantile_crc = only_correct_runs %>% 
    select(percentage) %>% 
    pull() %>% 
    quantile() %>%
    t() 
    

knitr::kable(combined_runs_correct_2, caption = "Overiew of `correct` and `not correct` values in each run")
knitr::kable(quantile_crc, col.names = c("Min Correct",
           "Q1 Correct",
           "Average Correct",
           "Q3 Correct",
           "Max Correct") , caption = "Quantiles of `correct` answers on the entire course runs")
```
Figure 1 retrieves the overall total of all participants answers in each course
run and extracts the percentage of `correct` and `not correct` answers, then 
makes a stack bar plot. This results in an easier way to interpret course run
performance individually.

After that, the line plot on top of the barplot shows the trend of percentage 
of `correct` answers over the course runs. This helps to see visually if there 
the trend improving or worsening across course runs.

Table 9 is a summary table that accompanies Figure 1 by showing the exact values 
that is being represented in the figure, it is also show the number of total 
of `correct` and `not correct` answers made in each run.

Table 10 is the quantiles for percentage of `correct` answers for all of runs in
total. This helps to see the least, quartiles, average and largest values of 
the percentage of `correct`.

## **Evaluation**

...


## **Deployment**

...

# Cycle 2

...
